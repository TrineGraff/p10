for(k in 0:length(y.ar.test) - 1) {
y = data[(p + 1):(length(y.train) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = y.ar.train[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(y.ar.train) + k):(length(y.ar.train) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fcAR(y.ar.train, y.ar.test, 4)
cAR= function(y.train, y.test, p) {
fc = c(NA)
for(k in 0:length(y.ar.test) - 1) {
y = data[(p + 1):(length(y.train) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = y.ar.train[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(y.ar.train) + k):(length(y.ar.train) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fcAR(y.ar.train, y.ar.test, 4)
fcAR= function(y.train, y.test, p) {
fc = c(NA)
for(k in 0:length(y.ar.test) - 1) {
y = data[(p + 1):(length(y.ar.train) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = y.ar.train[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(y.ar.train) + k):(length(y.ar.train) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fcAR(y.ar.train, y.ar.test, 4)
fcAR= function(y.train, y.test, p) {
fc = c(NA)
for(k in 0:length(y.ar.test) - 1) {
y = y.train[(p + 1):(length(y.ar.train) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = y.ar.train[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(y.ar.train) + k):(length(y.ar.train) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fcAR(y.ar.train, y.ar.test, 4)
ForecastAR= function(data, p, idx = idx) {
fc = c(NA)
for(k in 0:length(data[-c(1:idx)]) - 1) {
y = data[(p + 1):(length(data[1:idx]) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = data[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(data[1:idx]) + k):(length(data[1:idx]) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fc = ForecastAR(y.ar, 4, idx = idx )
library(matrixcalc)
library(tidyverse)
source("../data/setup_data.R")
setwd("~/Documents/AAU/10. semester/r codes/scripts")
source("../scripts/setup_data.R")
getFactors <- function(X, r) {
n.var <- ncol(X)
XTX <- crossprod(X)
X.eig <- eigen(XTX, symmetric = TRUE)
eig.vec <- X.eig$vectors
loadings <- eig.vec[, 1:r] * sqrt(n.var)
factors <- (X %*% loadings) / n.var
out <- list(
"factors" = factors,
"loading" = loadings
)
return(out)
}
estFactors <- function(X, ic = 1, trace = FALSE) {
#X <- as.matrix(X.df[, -1])
#X <- scale(X)
n.obs <- nrow(X)
n.var <- ncol(X)
r.max <- floor(10*log10(n.var))
ics <- rep(NA, r.max)
for (r in 1:r.max) {
est.r <- getFactors(X, r)
F.r <- est.r$factors
L.r <- est.r$loading
if(ic == 1) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log((n.var * n.obs) / n.var + n.obs)
} else if (ic == 2) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log(min(n.var, n.obs))
} else if (ic == 3) {
penalty <- r * log(min(n.var, n.obs)) / min(n.var, n.obs)
} else {
stop("Invalid information criterion argument")
}
V.r <- matrix.trace(crossprod(X - tcrossprod(F.r, L.r))) / (n.obs * n.var)
ics[r] <- log(V.r) + penalty
if (trace) cat("r =", r, "\tV =", V.r, "\tIC =", ics[r], "\n")
}
r.opt <- which.min(ics)
print(r.opt)
est.opt <- getFactors(X, r.opt)
factors.opt <- est.opt$factors
colnames(factors.opt) <- paste("F", 1:r.opt, sep = "")
df.out <- data.frame(dato.train, factors.opt) %>% tbl_df
return(df.out)
}
estFactors(X.train, ic = 1, trace = TRUE)
estFactors <- function(X, ic = 1, trace = FALSE) {
#X <- as.matrix(X.df[, -1])
#X <- scale(X)
n.obs <- nrow(X)
n.var <- ncol(X)
r.max <- 20
ics <- rep(NA, r.max)
for (r in 1:r.max) {
est.r <- getFactors(X, r)
F.r <- est.r$factors
L.r <- est.r$loading
if(ic == 1) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log((n.var * n.obs) / n.var + n.obs)
} else if (ic == 2) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log(min(n.var, n.obs))
} else if (ic == 3) {
penalty <- r * log(min(n.var, n.obs)) / min(n.var, n.obs)
} else {
stop("Invalid information criterion argument")
}
V.r <- matrix.trace(crossprod(X - tcrossprod(F.r, L.r))) / (n.obs * n.var)
ics[r] <- log(V.r) + penalty
if (trace) cat("r =", r, "\tV =", V.r, "\tIC =", ics[r], "\n")
}
r.opt <- which.min(ics)
print(r.opt)
est.opt <- getFactors(X, r.opt)
factors.opt <- est.opt$factors
colnames(factors.opt) <- paste("F", 1:r.opt, sep = "")
df.out <- data.frame(dato.train, factors.opt) %>% tbl_df
return(df.out)
}
estFactors(X.train, ic = 1, trace = TRUE)
estFactors <- function(X, ic = 1, trace = FALSE) {
#X <- as.matrix(X.df[, -1])
#X <- scale(X)
n.obs <- nrow(X)
n.var <- ncol(X)
r.max <- 20
ics <- rep(NA, r.max)
for (r in 1:r.max) {
est.r <- getFactors(X, r)
F.r <- est.r$factors
L.r <- est.r$loading
if(ic == 1) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log((n.var * n.obs) / n.var + n.obs)
} else if (ic == 2) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log(min(n.var, n.obs))
} else if (ic == 3) {
penalty <- r * log(min(n.var, n.obs)) / min(n.var, n.obs)
} else {
stop("Invalid information criterion argument")
}
V.r <- matrix.trace(crossprod(X - tcrossprod(F.r, L.r))) / (n.obs * n.var)
ics[r] <- log(V.r) + penalty
if (trace) cat("r =", r, "\tV =", V.r, "\tIC =", ics[r], "\n")
}
r.opt <- which.min(ics)
print(r.opt)
est.opt <- getFactors(X, r.opt)
factors.opt <- est.opt$factors
colnames(factors.opt) <- paste("F", 1:r.opt, sep = "")
df.out <- data.frame(dato.train, factors.opt) %>% tbl_df
return(df.out)
}
estFactors(X.train, ic = 2, trace = TRUE)
estFactors <- function(X, ic = 1, trace = FALSE) {
#X <- as.matrix(X.df[, -1])
#X <- scale(X)
n.obs <- nrow(X)
n.var <- ncol(X)
r.max <- 20
ics <- rep(NA, r.max)
for (r in 1:r.max) {
est.r <- getFactors(X, r)
F.r <- est.r$factors
L.r <- est.r$loading
if(ic == 1) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log((n.var * n.obs) / n.var + n.obs)
} else if (ic == 2) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log(min(n.var, n.obs))
} else if (ic == 3) {
penalty <- r * log(min(n.var, n.obs)) / min(n.var, n.obs)
} else {
stop("Invalid information criterion argument")
}
V.r <- matrix.trace(crossprod(X - tcrossprod(F.r, L.r))) / (n.obs * n.var)
ics[r] <- log(V.r) + penalty
if (trace) cat("r =", r, "\tV =", V.r, "\tIC =", ics[r], "\n")
}
r.opt <- which.min(ics)
print(r.opt)
est.opt <- getFactors(X, r.opt)
factors.opt <- est.opt$factors
colnames(factors.opt) <- paste("F", 1:r.opt, sep = "")
df.out <- data.frame(dato.train, factors.opt) %>% tbl_df
return(df.out)
}
estFactors(X.train, ic = 3, trace = TRUE)
estFactors <- function(X, ic = 1, trace = FALSE) {
#X <- as.matrix(X.df[, -1])
#X <- scale(X)
n.obs <- nrow(X)
n.var <- ncol(X)
r.max <- 20
ics <- rep(NA, r.max)
for (r in 1:r.max) {
est.r <- getFactors(X, r)
F.r <- est.r$factors
L.r <- est.r$loading
if(ic == 1) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log((n.var * n.obs) / n.var + n.obs)
} else if (ic == 2) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log(min(n.var, n.obs))
} else if (ic == 3) {
penalty <- r * log(min(n.var, n.obs)) / min(n.var, n.obs)
} else {
stop("Invalid information criterion argument")
}
V.r <- matrix.trace(crossprod(X - tcrossprod(F.r, L.r))) / (n.obs * n.var)
ics[r] <- log(V.r) + penalty
if (trace) cat("r =", r, "\tV =", V.r, "\tIC =", ics[r], "\n")
}
r.opt <- which.min(ics)
print(r.opt)
est.opt <- getFactors(X, r.opt)
factors.opt <- est.opt$factors
colnames(factors.opt) <- paste("F", 1:r.opt, sep = "")
df.out <- data.frame(dato.train, factors.opt) %>% tbl_df
return(df.out)
}
estFactors(X.train, ic = 2, trace = TRUE)
estFactors <- function(X, ic = 1, trace = FALSE) {
#X <- as.matrix(X.df[, -1])
#X <- scale(X)
n.obs <- nrow(X)
n.var <- ncol(X)
r.max <- 20
ics <- rep(NA, r.max)
for (r in 1:r.max) {
est.r <- getFactors(X, r)
F.r <- est.r$factors
L.r <- est.r$loading
if(ic == 1) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log((n.var * n.obs) / n.var + n.obs)
} else if (ic == 2) {
penalty <- r * (n.var + n.obs) / (n.var * n.obs) * log(min(n.var, n.obs))
} else if (ic == 3) {
penalty <- r * log(min(n.var, n.obs)) / min(n.var, n.obs)
} else {
stop("Invalid information criterion argument")
}
V.r <- matrix.trace(crossprod(X - tcrossprod(F.r, L.r))) / (n.obs * n.var)
ics[r] <- log(V.r) + penalty
if (trace) cat("r =", r, "\tV =", V.r, "\tIC =", ics[r], "\n")
}
r.opt <- which.min(ics)
print(r.opt)
est.opt <- getFactors(X, r.opt)
factors.opt <- est.opt$factors
colnames(factors.opt) <- paste("F", 1:r.opt, sep = "")
df.out <- data.frame(dato.train, factors.opt) %>% tbl_df
return(df.out)
}
estFactors(X.train, ic = 1, trace = TRUE)
source("../scripts/setup_data.R")
library(selectiveInference)
# Forfatter: Ryan Tibshirani, Rob Tibshirani, Jonathan Taylor,
# Joshua Loftus, Stephen Reid
# main fcts: lar, larInf, fixedLassoInf
set.seed(1)
lasso.model <- glmnet(X.train, y.train, alpha = 1, standardize = FALSE, intercept = FALSE)
cv.lasso <- cv.glmnet(X.train, y.train, alpha = 1, standardize = FALSE, intercept = FALSE)
plot(cv.lasso)
best_lambda <- cv.lasso$lambda.1se
best_lambda
log(best_lambda)
source("data_unrate.R")
setwd("~/Desktop/p10/R/unrate/autoregressive_model")
setwd("~/Desktop/p10/R/unrate")
source("data_unrate.R")
source("package.R")
# Forecast - AR -----------------------------------------------------------
ForecastAR= function(data, p, idx = idx) {
fc = c(NA)
for(k in 0:length(data[-c(1:idx)]) - 1) {
y = data[(p + 1):(length(data[1:idx]) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = data[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(data[1:idx]) + k):(length(data[1:idx]) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fc = ForecastAR(y, 4, idx = idx )
plot(fc$fc, type = "l", col = "red", xlim = c(0,140), ylim = c(-0.5, 0.5))
par(new = TRUE)
plot(y_test, type = "l", xlim = c(0,140), ylim = c(-0.5, 0.5))
dato = c(as.character(test_dato))
df = data.frame(date = as.Date(dato), fc = fc$fc, y = y_test)
dato = c(as.character(dato_test))
df = data.frame(date = as.Date(dato), fc = fc$fc, y = y_test)
ggplot(df, aes(x = date ))  +
geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line(aes(y = fc, colour = "AR(4)")) +
ylab("Rate") + xlab("Dato") +
scale_colour_manual(values = c("red", "gray")) +
theme(legend.title=element_blank())
ggplot(df, aes(x = date ))  +
geom_line(aes(y = y, colour = "Arbejdsløshed")) +
ylab(" ") + xlab(" ") +
#scale_colour_manual(values = c("red", "gray")) +
theme(legend.title=element_blank())
ggplot(df, aes(x = date ))  +
geom_line(aes(y = y)) +
ylab(" ") + xlab(" ") +
#scale_colour_manual(values = c("red", "gray")) +
#theme(legend.title=element_blank())
ggplot(df, aes(x = date ))  +
geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line(aes(y = fc, colour = "AR(4)")) +
ylab("Rate") + xlab("Dato") +
scale_colour_manual(values = c("red", "gray")) +
theme(legend.title=element_blank())
ggplot(df, aes(x = date ))  +
geom_line(aes(y = y, colour = "Arbejdsløshed")) +
ylab(" ") + xlab(" ") +
#scale_colour_manual(values = c("red", "gray")) +
#theme(legend.title=element_blank())
ggplot(df, aes(x = date ))  +
geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line(aes(y = fc, colour = "AR(4)")) +
ylab("Rate") + xlab("Dato") +
scale_colour_manual(values = c("red", "gray")) +
theme(legend.title=element_blank())
ggplot(df, aes(x = date, y = y ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ") +
#scale_colour_manual(values = c("red", "gray")) +
#theme(legend.title=element_blank())
ggplot(df, aes(x = date ))  +
geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line(aes(y = fc, colour = "AR(4)")) +
ylab("Rate") + xlab("Dato") +
scale_colour_manual(values = c("red", "gray")) +
theme(legend.title=element_blank())
ggplot(df, aes(x = date, y = y ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
ggplot(df, aes(x = date, y = y_train ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
date = as.Date(dato)
date
date = as.Date(dato_train)
date
df_1 <- data.frame(date = as.Date(dato_train), y = y_train)
df_1
ggplot(df1, aes(x = date, y = y_train ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
ggplot(df_1, aes(x = date, y = y_train ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
library(ggplot2)
library(gridExtra)
df <- read.csv("../data/transformed_data.csv")
unrate_sta_scale <- scale(df$UNRATE, scale = FALSE)
df
dato <- c(as.character(df$dato[1:552]))
dato
df_scale <- data.frame(date = as.Date(dato), unrate_sta_scale)
dato <- c(as.character(df$dato))
df_scale <- data.frame(date = as.Date(dato), unrate_sta_scale)
df_scale
ggplot(df_scale, aes(x = dato, y = unrate_sta_scale ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
df_scale <- data.frame(date = as.Date(dato), y = unrate_sta_scale)
df_scale
ggplot(df_scale, aes(x = dato, y = y ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
source("data_unrate.R")
source("package.R")
dato = c(as.character(dato_test))
df = data.frame(date = as.Date(dato), fc = fc$fc, y = y_test)
# Forecast - AR -----------------------------------------------------------
ForecastAR= function(data, p, idx = idx) {
fc = c(NA)
for(k in 0:length(data[-c(1:idx)]) - 1) {
y = data[(p + 1):(length(data[1:idx]) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = data[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(data[1:idx]) + k):(length(data[1:idx]) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fc = ForecastAR(y, 4, idx = idx )
dato = c(as.character(dato_test))
df = data.frame(date = as.Date(dato), fc = fc$fc, y = y_test)
df_1 <- data.frame(date = as.Date(dato_train), y = y_train)
ggplot(df_1, aes(x = date, y = y_train ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
dato <- c(as.character(df$dato))
library(ggplot2)
library(gridExtra)
FRED_MD <- read.csv("../data/FRED_MD/current.csv", sep = ",", header = TRUE)
dato <- as.Date(FRED_MD[-1, 1], format = "%m/%d/%Y")
rawdata <- FRED_MD[-1, -1]
df_raw <- data.frame(dato, rawdata)
unrate <- ggplot(df_raw, aes(dato, UNRATE)) + geom_line() +
xlab(" ") +
ylab(" ")
df <- read.csv("../data/transformed_data.csv")
unrate_sta_scale <- scale(df$UNRATE, scale = FALSE)
dato <- c(as.character(df$dato))
df_scale <- data.frame(date = as.Date(dato), y = unrate_sta_scale)
ggplot(df_scale, aes(x = dato, y = y ))  +
geom_line() +
ylab(" ") + xlab(" ")
source("data_unrate.R")
source("package.R")
# Forecast - AR -----------------------------------------------------------
ForecastAR= function(data, p, idx = idx) {
fc = c(NA)
for(k in 0:length(data[-c(1:idx)]) - 1) {
y = data[(p + 1):(length(data[1:idx]) + k)]
n = length(y)
x.lag = matrix(nrow = n, ncol = p)
for (j in 1:p){
for (i in 1:n){
x.lag[i, j] = data[p + i - j]
}
}
beta.hat = solve(crossprod(x.lag), crossprod(x.lag, y))
fc[k+1] = data[(length(data[1:idx]) + k):(length(data[1:idx]) + k - p + 1)] %*% beta.hat
}
print(list("fc" = fc))
}
fc = ForecastAR(y, 4, idx = idx )
dato11 = data_raw$dato
dato1 = c(as.character(dato11))
df_1 <- data.frame(date = as.Date(dato1), y = y)
df_1
ggplot(df_1, aes(x = dato1, y = y_train ))  +
#geom_line(aes(y = y, colour = "Arbejdsløshed")) +
geom_line() +
ylab(" ") + xlab(" ")
length(y)
length(dato1)
df_1
ggplot(df_1, aes(x = date, y = y_train ))  +
geom_line() +
ylab(" ") + xlab(" ")
ggplot(df_1, aes(x = date, y = y ))  +
geom_line() +
ylab(" ") + xlab(" ")

\chapter{Faktor modellen}
\textit{I dette kapitel introduceres faktor modellen, som kan reducere antallet af variable til et mindre andtal faktorer, der beskriver data. 
Kapitlet er baseret på \citep{stock_watson_2002a}} \\[2mm]
%
Faktor modellen er givet ved
\begin{align}
X_t = \Lambda F_t + e_t, \label{eq:factor_model}
\end{align}
hvor \(\Lambda\) er en \(N \times r\) matrix, \(F_t\) er en \(r \times 1\) vektor af faktorer og \(e_t\) er en \(N \times 1\) vektor af fejlled.

Nedenfor introduceres nogle modelantagelse.
%
\begin{ass}[Faktorer og faktor loadings] \label{ass:faktor}
\begin{enumerate}
\item \(N^{-1} \Lambda^T \Lambda \rightarrow I_r\)
\item \(\E{F_t F_t^T} = \Sigma_{FF}\), hvor \(\Sigma_{FF}\) er en diagonalmatrix med indgange \(\sigma_{ii} > \sigma_{jj} > 0\) for \(i < j\)
\item \(\abs{\lambda_{i,m}} \leq \bar{\lambda} < \infty\) for \(i = 1, \ldots, N\) og \(m = 1, \ldots, r\)
\item \(T^{-1} \sum_{t=1}^T F_t F_t^T \overset{p}{\rightarrow} \Sigma_{FF}\) 
\end{enumerate}
\end{ass}
%
Antagelse \(\ref{ass:faktor}\) er nødvendige for at identificere faktorerne.
Da \(\Lambda F_t = \Lambda R R^{-1} F_t\) for enhver ikke-singulær matrix \(R\), er normaliseringen påkrævet for entydig at definere faktorerne.
Dvs at modellen med faktor loadings \(\Lambda R\) og faktorer \(R^{-1} F_t\) er ækvivalent med modellem med faktor loadings \(\Lambda\) og faktorer \(F_t\).
Antagelse \ref{ass:faktor}.a) restringerer \(R\) til at være en ortonormal matrix mens antagelse \ref{ass:faktor}.b) yderligere restringerer \(R\) til at være en diagonal matrix med diagonal elementerne \(\pm 1\).
Herfra vil vi kunne bestemme faktorerne op til fortegnsfejl.

Antagelse \ref{ass:faktor} tillader faktorerne at være korreleret, men også lags af faktorerne at være korreleret.

Makroøkonomiske tidsrækker er sjældent i.i.d. og normalfordelte fejlled, da tidrækkerne er korreleret. 
Derfor har vi følgende antagelser for fejlledene.
%
\begin{ass}[Momenter af fejlene \(e_t\)] \label{ass:momenter_fejl}
\begin{enumerate}
\item \(\lim_{N \rightarrow \infty} \sup_t \sum_{u = - \infty}^\infty \abs{\E{N^{-1} e_t^T e_{t+u}}} < \infty\)
\item \(\lim_{N \rightarrow \infty} \sup_t N^{-1} \sum_{j = 1}^N \abs{\E{e_{it} e_{jt}}} < \infty\)
\item \(\lim_{N \rightarrow \infty} \sup_{t,s} N^{-1} \sum_{i=1}^N \sum_{j=1}^N \abs{\text{cov}\del{e_{is} e_{it}, e_{js} e_{jt}}} < \infty\)
\end{enumerate}
\end{ass}
%
Antagelse \ref{ass:momenter_fejl}.a) tillader serial korrelation for \(e_{it}\) processerne.
Antagelse \ref{ass:faktor}.b) tillader \(\cbr{e_{it}}\) at være svagt korreleret på tværs af tidsrækkerne.
Vi antager ikke normalitet, men \ref{ass:faktor}.c) begrænser størrelsen af fjerde momenter.

Faktormodellen forecastes udfra
\begin{align}
y_{t+h} = \beta_F^T F_t + \beta_\omega^T \omega_t + \epsilon_{t+h} \label{eq:forecast_ligning_faktor}
\end{align}
Vi antager, at forecasten er well behaved således at hvis \(\cbr{F_t}\) er observeret, da vil mindste kvadraters metode give en konsistent estimator af regressions koefficienterne.
%
\begin{ass} \label{ass:forecasting_ligning}
Lad \(z_t = \del{F_t^T, \omega_t^T}\) og \(\beta = \del{\beta_F^T, \beta_\omega^T}\), da gælder følgende
\begin{enumerate}
\item \(\E{z_t z_t^T} = \Sigma_{zz} = \begin{pmatrix}
\Sigma_{FF} & \Sigma_{F \omega} \\
\Sigma_{\omega F} & \Sigma_{\omega \omega}
\end{pmatrix} \) er en positiv definit matrix.
\item \(T^{-1} \sum_{t=1}^T z_t z_t^T \overset{p}{\rightarrow} \Sigma_{zz}\)
\item \(T^{-1} \sum_{t=1}^T z_t \epsilon_{t+h} \overset{p}{\rightarrow} 0\)
\item  \(T^{-1} \sum_{t=1}^T \epsilon_{t+h}^2 \overset{p}{\rightarrow} \sigma^2\)
\item \(\abs{\beta} < \infty\) 
\end{enumerate}
\end{ass}
%
Antagelse \ref{ass:forecasting_ligning}.a)-\ref{ass:forecasting_ligning}.c) medfører at regression af \(y_{t+h}\) på \(z_t\) giver konsistent OLS estimatorer.
De yderligere antagelser er nødvendige for at sikre, at OLS regressions koefficienterne i regressionen af \(y_{t+h}\) på \(\del{\hat{F}_t^T, \omega_t^T}\), hvor \(F_t\) altså ikke er observeret.


Inden prædiktion skal vi estimerer faktorerne og bestemme antallet af faktorer.
Nedenfor introduceres nogle metoder til at estimerer faktorerne.

\section{Estimation af faktorer}
I --- præsenteres flere metoder til dette formål.
Først anvende gaussian maksimum likelihood estimation med kalman filteret.
nonparametrisk estimation med averaging metoder.
-----

Vi undgår skæringen og antager at data er transformeret til at være stationært.
dvs standaridiser variablerne.



%Først opskrives DFM som en lineær state space model.
%Lad $p$ være ordenen af lag polynomiet $\lambda(L)$, lad $F_t=(f_t^T,f_{t-1}^T,\ldots,f_{t-p}^T)^T$ betegne en $r \times 1$ vektor og lad $\Lambda=(\lambda_0,\lambda_1,\ldots,\lambda_p)$, hvor $\lambda_i$ er en $n \times q$ matrix med koefficienter af det $i$'te lag i $\lambda(L)$.
%Tilsvarende, lader vi $\Phi(L)$ være en matrix bestående af 0 og 1, og elementerne af $\Psi(L)$ således at vektor autoregressionen i \eqref{eq:dfm2} er skrevet udfra $F_t$.
%Med denne notation kan DFM omsrives til
%\begin{align}
%X_t &= \Lambda F_t + e_t \label{eq:dfm4}\\
%\Phi(L) F_t &= G \eta_t, \label{eq:dfm5}
%\end{align}
%hvor $G$ er en matrix bestående af 0 og 1 som vælges således at \eqref{eq:dfm5} og \eqref{eq:dfm2} er ækvivalente.

Motivationen for at betragte tværsnit averaging af \(X_t\) til estimation af faktorerne er at de vægtede gennemsnit af idiosyncratisk disturvances vil konvergere mod nul af store tals lov, således at det kun er den lineære kombinationer af faktorerne som forbliver.
Disse tværsnits averaging estimationerer er baseret på den statisk repræsentation i \eqref{eq:dfm4}.
Estimatorerne er nonparametrisk, da de ikke kræver en parametrisk model for faktorerne \(F_t\) eller for dynamikken af isiosyncratisk.
Istedet behandles \(F_t\) som en \(r\) dimensionel parameter der skal estimeres udfra en \(N\)-dimensional datavektor \(X_t\).

Principal komponent estimatoren kan udledes udfra følgende mindste kvadraters problem
\begin{align}
\min_{F_1,\ldots,F_T, \Lambda} \cbr{\frac{1}{NT} \sum_{t=1}^T(X_t-\Lambda F_t)^T(X_t - \Lambda F_t)}, \ \text{underlagt at } N^{-1} \Lambda^T \Lambda = I_r. \label{eq:dfm11}
\end{align}
For at løse optimeringsproblemet \eqref{eq:dfm11} differentieres objektfunktionen mht \(F_t\), dette udtryk sættes lig 0 og vi isoleres for \(F_t\), hvoraf vi får, at
\begin{align}
\frac{\partial}{\partial F_t} \del{(X_t-\Lambda F_t)^T(X_t - \Lambda F_t)} = -2 \Lambda^T X_t + 2 \Lambda^T \Lambda F_t \quad \Longrightarrow \quad \hat{F}_t = \del{\Lambda^T \Lambda}^{-1} \Lambda^T X_t. \label{eq:dfm12}
\end{align}
Hvis vi indsætter \eqref{eq:dfm12} i \eqref{eq:dfm11} fås concentrate objektfunktion
\begin{align*}
\min_{\Lambda} \cbr{\frac{1}{NT} \sum_{t=1}^T \del{X_t^T X_t - 2 F_t^T \Lambda^T X_t + F_t^T \Lambda^T \Lambda F_t}} \\
\min_\Lambda \frac{1}{T} \sum_{t=1}^T X_t^T \sbr{I- \Lambda \del{\Lambda^T \Lambda}^{-1} \Lambda} X_t.
\end{align*}
Dette minimeringsproblem er ækvivalent til følgende maksimeringsproblem
\begin{align*}
\max_\Lambda \text{tr} \cbr{\del{\del{\Lambda^T \Lambda}^{-1/2}}^T \Lambda^T \del{T^{-1} \sum_{t=1}^T X_t X_t^T} \Lambda \del{\Lambda^T \Lambda}^{-1/2}},
\end{align*}
som er ækvivalent med $\max_\Lambda \Lambda^T \hat{\Sigma}_{XX} \Lambda$ underlagt at $N^{-1} \Lambda^T \Lambda=I_r$, hvor $\hat{\Sigma}_{XX}=T^{-1} \sum_{t=1}^T X_t X_t^T$.
Løsningen til dette problemet findes ved at sætte \(\hat{\Lambda}\) lig med de skalerede egenvektorer af \(\hat{\Sigma}_{XX}\), svarende til dens \(r\) største egenværdier.
dvs \(\Lambda\) konstrueres som \(\sqrt{n} \cdot \nu_r\), hvor \(\nu_r\) er egenvektorerne svarende til de \(r\) største egenværdier af \(\X^T \X\).

Da $\hat{\Lambda}^T \hat{\Lambda}=N I_r$ følger det af mindste kvadraters estimatoren af $F_t$ er $\hat{F}_t=\hat{F}_t \del{N^{-1}\hat{\Lambda}}=N^{-1}\hat{\Lambda}^TX_t$, som er de skalerede $r$ første principal komponenter af $X_t$. 

Hvis \(N > T\), kan løsningen udregnes simplere ved at koncentrere \(\Lambda\) ud istedet for \(F_t\).
%
\\[4mm]
%
%
De principale komponenter udregnes ved at første komponent beskriver så meget af variation i data som muligt, dvs at den har den største varians, anden komponent er da en lin kombination af variablerne som er ukorreleret med den første principal komponent og den har den største varians underlagt denne betingelse.
Dvs hver komponent har den største muligt varians under betingelsen af den er ortgonal til de foregående komponenter.
Dvs den nye tidsrækker er ukorreleret og den første principal komponenter i tidsrækkerne har det største variantion i den originale tidsrækker.


PCA
statistisk procedure der anvender en ortogonal transformation til at konverterer en mængde observationer af korrelerede variable til en mængde af værdier af ukorreleret variable, som kaldes principale komponenter (PC)
Denne transformation defineres således at første PC har den størst mulige varians, og hver efterfølgende PC har igen den størst mulige varians givet de foregående PC er ortogonale.

\subsection{Konsistens af estimatorer}

\begin{thm} \label{thm:factorthm1}
Lad \(S_i\) betegne en variabel med værdi \(\pm 1\), lad \(N, T \rightarrow \infty\) og antag at antagelse \ref{ass:faktor} og \ref{ass:momenter_fejl} er opfyldt.
Antag yderligere at \(k\) faktorer bliver estimeret.
Da kan \(S_i\) vælges således at følgende gælder:
\begin{enumerate}
\item \(T^{-1} \sum_{t=1}^T \del{S_i \hat{F}_{it} - F_{it}}^2 \overset{p}{\rightarrow} 0\), for \(i=1, \ldots, r\).
\item \(S_i \hat{F}_{it} \overset{p}{\rightarrow} F_{it}\), for \(i=1, \ldots, r\).
\item \(T^{-1} \sum_{t=1}^T \hat{F}_{it}^2 \overset{p}{\rightarrow} 0\), for \(i=r+1, \ldots, k\).
\end{enumerate}
\end{thm}


De principal komponent estimatorer er punktvis konsistent og har begrænset middelkvadratfejl (MSE) som konvergerer i sandsynlighed mod 0.
Da antagelse \ref{ass:faktor} ikke identificerer fortegnet af faktorerne, er sætningen kun givet i forhold til fortegns justerede estimatorer.



Estimationen vil være markant simplificeret hvis \(\Lambda\)  er kendt, da \(F_t\)  kunne estimeres udfra mindste kvadraters regression af \(\cbr{x_{it}}_{i=1}^N\) på \(\cbr{\lambda_i}_{i=1}^N\).
Konsistent af den resulterende estimator vil studeres ved at analyser \(\hat{F}_t - F_t = \del{\Lambda^T \Lambda / N}^{-1} \del{N^{-1} \sum_{i=1}^N \lambda_i e_{it}}\).
For \(N \rightarrow \infty\) gælder at \(\Lambda^T \Lambda / N \overset{p}{\rightarrow} I_r\) af antagelse \ref{ass:faktor}.a) og \(N^{-1} \sum_{i=1}^N \lambda_i e_{it} \overset{p}{\rightarrow} 0\) af antagelse \ref{ass:momenter_fejl}.a) og \ref{ass:faktor}.c), hvoraf konsistens af \(\hat{F}_t\) følger direkte.
Hvis istedet \(F\) er kendt, da kan \(\lambda_i\) estimeres udfra regression \(\cbr{x_{it}}_{i=1}^N\) på \(\cbr{F_{t}}_{t=1}^T\) og konsistens kunne analysere ved at undersøge \(\del{T^{-1} \sum_{t=1}^T F_t F_t^T}^{-1} T^{-1} \sum_{t=1}^T F_t e_{it}\) for \(T \rightarrow \infty\) på lignende vis.

Da både \(F\) og \(\Lambda\) er ukendt, kræves at \(N, T \rightarrow \infty\), hvilket er betydeligt sværere at bevise.
Strategien for beviset er at vise at de første \(r\) egenvektorer af \(\del{NT}^{-1} X^T X\) opfører sig som de første \(r\) egenvektorer af \(\del{NT}^{-1} \Lambda^T F^T F \Lambda\), og da vise at disse egenvektorer kan bruges til at konstruere en konsistent estimator af \(F\).

Næste resultat viser feasible forecast, som konstrueres udfra de estimerede faktorer og estimerede parametre, konvergerer til det optimale infeasible forecast, og dermed er asymptotisk efficient.
Yderligere vises at de feasible regressions koefficient estimatorer er konsistente.

Resultatet antager at forecast ligningen er estimeret ved at anvende \(k=r\) faktorer.
Dette tager lidt generalitet, da der er flere metoder for ...

\begin{thm}
Antag antagelse \ref{ass:forecasting_ligning} og betingelserne i sætning \ref{thm:factorthm1} er opfyldt. 
Lad \(\hat{\beta}_F\) og \(\hat{\beta}_\omega\) betegne OLS estimaterne af \(\beta_F\) og \(\beta_\omega\) fra regressionen af \(\cbr{y_{t+h}}_{t=1}^{T-h}\) på \(\cbr{\hat{F}_t, \omega_t}_{t=1}^{T-h}\). Da gælder følgende
\begin{enumerate}
\item \(\del{\hat{\beta}_F^T \hat{F}_T + \hat{\beta}_\omega \omega_T} - \del{\beta_F^T F_T + \beta_\omega \omega_T} \overset{p}{\rightarrow} 0\).
\item \(\hat{\beta}_\omega - \beta_\omega \overset{p}{\rightarrow} 0\) og \(S_i\) defineret i sætning \ref{thm:factorthm1} kan vælges således at \(S_i \hat{\beta}_{iF} - \beta_{iF} \overset{p}{\rightarrow} 0\) for \(i = 1, \ldots, r\).
\end{enumerate}
\end{thm}
\begin{proof}
Først bevises b). 
Lad \(\hat{\beta}\) være opdelt som \(\hat{\beta} = \del{\hat{\beta}_z^T \hat{\beta}_\omega^T}^T\), da skal vi vise at \(\hat{\beta}_\omega - \beta_\omega \overset{p}{\rightarrow} 0\) og \(S_i \hat{\beta}_{iz} \overset{p}{\rightarrow} 0\) for \(i = 1, \ldots, r\).
Vi opskriver
\begin{align*}
\begin{pmatrix}
S \hat{\beta}_z \\ \hat{\beta}_w
\end{pmatrix} - \begin{pmatrix}
\beta_z \\ \beta_w
\end{pmatrix} &= \begin{pmatrix}
T^{-1} \sum_{t=1}^T \hat{F}_t \hat{F}_t^T & T^{-1} S \sum_{t=1}^T \hat{F}_t w_t^T \\
T^{-1} \sum_{t=1}^T w_t \hat{F}_t^T S & T^{-1} \sum_{t=1}^T w_t w_t^T
\end{pmatrix}^{-1} \begin{pmatrix}
T^{-1} S \sum_{t=1}^T \hat{F}_t \epsilon_{t+h} \\
T^{-1} \sum_{t=1}^T w_t \epsilon_{t+h}
\end{pmatrix} \\
&\overset{p}{\rightarrow} \begin{pmatrix}
\Sigma_{FF} & \Sigma_{Fw} \\ \Sigma_{wF} & \Sigma_{ww}   
\end{pmatrix}^{-1} \begin{pmatrix}
0 \\ 0
\end{pmatrix} = 0.
\end{align*}

Herefter bevises a).

Lad \(\hat{z}_t = \del{\hat{F}_t, \omega_t^T}\) og \(\hat{\beta} = \del{\sum_{t=1}^{T-h} \hat{z}^T \hat{z}}^{-1} \del{\sum_{t=1}^{T-h} \hat{z}_t y_{t+h}}\), da gælder, at \(\hat{\beta}^T \hat{z}_T - \beta^T z_T \overset{p}{\rightarrow} 0\).
Dette ses ved at lade \(R = \begin{pmatrix}
S & 0 \\ 0 & I_p
\end{pmatrix}\), hvor \(p\) betegner antallet af elementer i \(\omega_t\), da fås
\begin{align*}
\hat{\beta}^T \hat{z}_T - \beta^T z_T &= \del{R \hat{\beta}}^T R \hat{z}_T - \beta^T z_t \\
&= \del{R \hat{\beta} - \beta}^T z_T + \del{R \hat{\beta}}^T \del{R \hat{z}_T - z_T}
\end{align*}
\end{proof}




\section{Valg af antal faktorer}
Der findes flere metoder til at estimere antallet af static faktorer $r$ og antallet af dynamiske faktorer $q$.
Der findes ikke en definit definition.
Men den totale varians, den relative størrelse af egenværdierne (variansen af sample komponenterne), bør tages i betragtning.
En komponent med tilhørende egenværdi omkring nul, ses som værende ikke vigtig, kan indikere en uventet afhængighed i data.





Antallet af faktorer kan bestemmes udfra et \textit{scree plot}.
Her er egenværdierne ordnede fra den største til den mindste.
For at bestemme antallet af faktorer ser vi efter en bøjning i scree plot.
Antallet af komponenter er givet ved punktet hvori de resterende egenværdier er relativ lav og approksimativ samme størrelse.

Antallet af faktorer kan baseres på informationskriterier.
\citep{Bai_Ng} 
Informationskriterierne betragter tradeoff mellem at inkludere en ekstra faktor, dvs en ekstra parameter i modellen, mod omkostningen af at øge variabiliteten som kommer af at estimere en anden parameter.
Dette gøres ved at minimere en penalized likelihood, hvor straffaktoren stiger lineært med antallet af faktorer.

For dynamiske faktor modeller betragtes
\begin{align*}
\text{IC} \del{r} = \ln V_r \del{\hat{\Lambda}, \hat{F}} + r g \del{N,T}
\end{align*}
hvor \(V_r \del{\hat{\Lambda}, \hat{F}}\) er objektfunktionen i \eqref{eq:dfm11} evalueret i de principielle komponenters estimatorer \(\del{\hat{\Lambda}, \hat{F}}\) og hvor \(g \del{N,T}\) er en straffaktor således at \(g \del{N,T} \rightarrow 0\) og \(\min \cbr{N, T} \cdot g \del{N,T} \rightarrow \infty\) når \(N, T \rightarrow \infty\).

Tre af straffaktionerne foreslået af \citep{Bai_Ng} er
\begin{align*}
g_1 \del{N,T} &= \frac{N + T}{N T} \ln \del{\frac{NT}{N + T}}, \\
g_2 \del{N,T} &= \frac{N + T}{N T} \ln \del{ \min \cbr{N, T}}, \\
g_3 \del{N,T} &= \frac{\ln \del{\min \cbr{N, T}}}{\min \cbr{N, T}},
\end{align*}
som resulterer i kriterierne der betegnes henholdsvis \(\text{IC}_1 \del{r}\), \(\text{IC}_2 \del{r}\) samt \(\text{IC}_3 \del{r}\).

For \(N = T\) fås at \(g_2 \del{T,T} = 2T^{-1} \ln \del{T}\), som bekendt er \(2\) gange BIC straffaktoren.

\citep{Bai_Ng} viste, at under betingelserne af approksimativ dfm, da er \(\hat{r}\) som minimere et af informationskriterierne med \(g \del{N,T}\) opfylder disse betingelser konsistent for den sande værdi af \(r\), under antagelse af at værdien af \(r\) er endelig og ikke stiger med \(\del{N, T}\).



Estimation
De dynamiske faktorer estimeres ikke-parametrisk udfra principal komponent analyse.

Betragt en ikke-lineær mindste kvadraters objekt funktion
\begin{align*}
V \del{h}
\end{align*}









Formålet med faktor analyse er at beskrive covariansen mellem variable i form af nogle underliggende, ikke observerbare stokatiske mængder kaldet faktorer.
Faktor modellen er motiveret af: antag variablerne kan grupperes ved der korrelationer.
Dvs antag at variablerne indenfor en bestemt gruppe er højt korreleret med hinanden, men relativ lav korreleret med variablerne i andre grupper.
Faktor analyse kan betragtes som en udvidelse af principal component analyse.
Begge kan anses som et forsøg på at approksimere kovarians matricen \(\Sigma\).


\chapter{Lasso modellen og dens generaliseringer}
Da den autoregressive model valgte en orden på 4, tilføjes fire variable med laggede værdier af arbejdsløshedsraten til de øvrige 122 variable.
Dette introducerer nogle uobserveret værdier, og derfor fjernes de første 4 observationer af hver tidsrækkede, således at vi undgår uobserveret værdier.
De tilføjede laggede tidsrækker inkluderes i gruppe 2, hvor også arbejdsløshedsraten er inkluderet (se appendiks \ref{app:data}).
Vi betragter derfor 126 variable i perioden fra 1. maj 1960 til 1. december 2005 svarende til 448 observationer.

Lasso problemet og dens generaliseringer kan løses med coordinate descent algoritmen og LARS algoritmen.
Vi vil anvende coordinate descent algoritmen til at løse lasso, ridge regression, elastisk net, group lasso og adaptive lasso med henholdsvis OLS og lasso vægte.
Men vi har valgt blot at betragte LARS algoritmen uden og med lasso modifikationen, for at begrænse den empiriske del.

\input{main/ch/sub/coordinate}
\input{main/ch/sub/lars}


%Vi vil først finde $\widehat\lambda$, som giver den optimale model for de forskellige shrinking metoder. 
%Vi har introduceret to algoritmer til at løse vores optimeringsproblemer, som vi vil anvende.
%Vi deler derfor vores analyse op i to dele  hhv. coordinate descent og LARS algoritmen.
%Herunder finder vi så  $\widehat\lambda$ ved hjælp af 10-fold krydsvalidering og BIC. 
%Når vi estimerer $\widehat\lambda$ ud fra krydsvalidering, ser vi ikke kun på den der giver mindst mulige krydsvaliderings fejl, der betegnes $\lambda_{\min}$, men også den største værdi således at fejlen er indenfor en standard afvigelse af minimum, som vi betegner $\lambda_{\text{1sd}}$.  
%For BIC finder vi $\widehat\lambda$ , ved det $\lambda$ som giver den mindste BIC. 
%
%Vi anvender funktionen \texttt{glmnet} fra R-pakken af samme navn til at estimerer modellerne lasso, elastik net, ridge og adaptive lasso's koefficienter.. 
%Funktionen genererer ud fra datasættet en følge på 100 $\lambda$-værdier og tilpasser en model til hver af disse ved maksimum likelihood estimation med algoritmen coordinate descent. 
%Ud fra dette anvender vi så 10-fold-krydsvalidering og BIC til at vælge $\widehat{\lambda}$, som giver den optimale model. 
%Det skal lige bemærkes, at for elastisk net har vi to turning parameter vi skal estimerer nemlig $\alpha$ og $\lambda$.  Så her har vi valgt 10 værdier af $\alpha$, hvor $\alpha \in [0,1]$. 
%For group lasso har vi anvendt \texttt{gglasso} fra R-pakken også med samme navn til at estimerer group lasso. 
%Denne funktion generer også en følge på 100 $\lambda$-værdier men anvender i stedet algoritmen black-wise descent.  Funktionen kræver også en gruppering af de forklarende variabler. 
%Vi anvender grupperne som er forslået af Michael McCracken, som ses i appendiks \ref{app:app_data}. Derudover har kvadratroden af gruppens størrelse som penality faktor. 
%For adaptive lasso med lasso vægte, anvender vi kun de forklarende variable, som lasso har udvalgt til at estimerer turning parameteren $\lambda$. 

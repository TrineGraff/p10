\subsection{Coordinate descent}
Vi anvender funktionen \texttt{glmnet} fra R-pakken af samme navn til at estimerer lasso, elastik net, ridge og adaptive lasso's koefficienter i vores modeller. Funktionen genererer ud fra datasættet en følge på 100 $\lambda$-værdier og tilpasser en model til hver af disse ved maksimum likelihood estimation med algoritmen coordinate descent. 
Ud fra dette anvender vi så 10-fold-krydsvalidering og BIC til at vælge $\widehat{\lambda}$, som giver den bedste model. 
Det skal lige bemærkes, at for elastisk net har vi to turning parameter vi skal estimerer nemlig $\alpha$ og $\lambda$.  Så her har vi valgt 10 værdier af  $\alpha$, hvor $\alpha \in (0,1)$. 
For group lasso har vi anvendt \texttt{gglasso} fra R-pakken også med samme navn til at estimerer group lasso. 
Funktionen generer også en følge på 100 $\lambda$-værdier men anvender i stedet algoritmen black-wise descent. 
Vi inddeller vores forklarende variabler i grupper. Vi anvender grupperne som er forslået af Michael McCracken, som ses i appendiks \ref{app:app_data}. Derudover har kvadratroden af gruppens størrelse som penality faktor. 

\subsubsection{Krydsvalidering}
I denne sektion anvender vi funktionen \texttt{cv.glmnet} i pakken \texttt{glmnet}. 
Figur \ref{fig:cv_plot} illusterer den gennemsnitlige krydsvaliderings fejl for hver værdi af $\log \lambda$ for hver af vores metoder.
Som nærvnt tidligere har elastisk net to turning parameter. Vi har derfor anvendt 10-fold krydsvalidering for 10 værdier af $\alpha$. Derfra har vi fundet  $\lambda_{\min}$ og krydsvaliderings fejlen for hver værdi af $\alpha$.  
Den mindste krydsvaliderings fejl for $\lambda_{\min}$ er når $\alpha =0.9$. 

\imgfigh{cv_plot.pdf}{1}{10-fold krydsvaliderings fejl plottede som en function af $ \log(\lambda)$ for vores metoder. De stiplede linjer indikerer minimum fejl, samt fejlen med en standard afvigelse af minimum}{cv_plot}

\input{fig/tab/cv_tab}

For at få et bedre overblik viser tabel  \ref{tab:cv_tab} værdierne af vores $\lambda$, antallet af koefficienter og deres krydvaliderings fejl. 
Vi ser for lasso og elastisk net, at der sker en reducering af antallet af parameter når $\lambda_{1\text{sd}}$ anvendes i forhold til $\lambda_{\min}$ og hvor deres MSE ikke er signifikant forskellig.  
Derfor lader vi den $\widehat{\lambda}$, for lasso og elastisk net være $\lambda_{1\text{sd}}$.
Vi ser dog også, at $\lambda_{1\text{sd}}$ er ens i tabel \ref{tab:cv_tab}. 
De afviger fra hinanden i 5. decimal.  

For ridge regression vil der ikke ske reducering af antallet af parameter, men derimod en reducering af værdierne af koefficienterne og derfor lader vi den $\widehat{\lambda}$, være den med mindst krydsvaliderings fejl og anvender $\lambda_{\min}$, som vores optimale $\lambda$. 
%
Men group lasso opfører sig anderledes end hvad vi havde forventet. 
Den fejler i reducering af parameter. 
Det indikerer lidt på, at group lasso ikke er en god model for vores data. (??)
Men vi lader $\widehat{\lambda}$, være $\lambda_{\min}$, da den har mindst krydsvaliderings fejl. 

Adaptive lasso m. OLS vægte vælger det færreste antal forklarende variabler. 
Den udvælger kun 2 for både  $\lambda_{\min}$ og $\lambda_{1\text{sd}}$. 
Derfor lader vi $\widehat{\lambda}$ være $\lambda_{\min}$. 

Det skal bemærkes, at når vi anvender adaptive lasso med lasso vægte anvender vi kun de forklarende variable, som lasso har udvalgt. 
Vi giver altså ikke alle 122 forklarende variable, men kun de 15, som $\widehat{\lambda}$ udvælger for lasso.
For adaptive lasso med lasso vægte lader vi $\widehat{\lambda}$ være $\lambda_{\min}$.  
Vi har markeret $\widehat{\lambda}$ for hver model med tykt i tabel  \ref{tab:cv_tab}. 

Tabel \ref{tab: lasso_ud} viser hvilke koefficienter elastisk net, lasso og adaptive lasso med ols og lasso vægte udvælger. 
Vi får at lasso og elastisk net udvælger de samme variable, dog er værdierne af koefficienterne forskellige. 
Det kan skyldes, at deres $\widehat{\lambda}$ værdi er tæt på den samme. 
Derudover har vi jo, at $\alpha = 1$ for lasso og $\alpha = 0.9$ for elastisk net, så der er altså ikke stor forskel på de to modeller. 
Derudover ses, at de fleste variabler de to metoder udvælger stammer fra samme gruppe, som vores responsvariable.  
For de to adaptive lasso modeller udvælger metoderne kun variable fra gruppen arbejdsmarked. 
Variablerne Civilian Labor Force og Civilian Employment bliver valgt af alle metoderne. 

\input{fig/tab/lasso_ud}

\newpage
\subsubsection{BIC}
I dette afsnit finder vi $\widehat{\lambda}$ med BIC. 
Tabel \ref{tab:bic_lambda} viser $\widehat{\lambda}$ værdi, BIC værdien og antallet af parameter. Vi ser igen at de to adaptive modeller udvælger færreste variabler og også den med de højeste værdier af $\widehat{\lambda}$. 
Igen ser vi at group lasso fejler i reducering af variable. Det tyder bestemt på, at det ikke er en god model til vores data. 
Tabel \ref{tab:bic_ud} viser hvilken forklarende variabler der bliver udvalgt udfra BIC. 
Vi kan se, at det er mange af de samme variabler der bliver anvendt for lasso og elastic net og igen ser vi at Civilian Labor Force og Civilian Employment bliver valgt af alle metoderne. 

\input{fig/tab/bic_lambda}
\input{fig/tab/bic_ud}

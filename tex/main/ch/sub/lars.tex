\section{Lars}
I denne sektion anvender vi algoritmen LARS til at løse vores problem og LARS algoritmen med en modifikation til at løse lasso. 
Vi anvender funktionerne \texttt{lars} fra R-pakken af samme navn. 
For LARS algoritmen producerer vi et fit, hver gang en ny variabler bliver tilføjet, dvs ved hvert step bliver der tilføjet en ny variable. Vi finder $\widehat{s}$, som betegner antallet af steps, ved krydsvalidering, men igen ser vi ikke kun på  $\widehat{s}_{\min}$, som giver den mindste gennemsnitlige krydsvaliderings fejl, men også den mindste værdi således at fejlen er indenfor en standard afvigelse, som betegnes $\widehat{s}_{\text{1sd}}$. 

Krydsvalideringen for lasso deler L1-normen op i en følge af 100 punkter mellem 0 og 1, hvor vi herefter finder $\widehat{f}$. Vi ser ikke kun på den model der giver den mindste krydsvaliderings fejl, som betegnes  $\widehat{f}_{\min}$, men også  $\widehat{f}_{\text{1sd}}$ . 
Figur \ref{fig:lars_kryds} viser krydsvaliderings plot for begge metoder. 
\imgfigh{lars_kryds.pdf}{1}{Viser 10-fold krydsvaliderings fejl plottede som en funktion af steps for metoden LARS, og en 10-fold krydsvaliderings fejl plottede som en funktion af fraktion af L1 normen}{lars_kryds}
\input{fig/tab/lars_lasso_tab}

\imgfigh{lars_lasso_coef.pdf}{0.6}{h}{lars_lasso_coef}
\imgfigh{lars_coef.pdf}{0.6}{h}{lars_coef}

%SE for CV is found from the sample SE of the squared errors
%choose fraction based 1-se cv error rule
%# largest value of lambda such that
%# error is within 1 standard error of the minimum:
%Krydsvalideringen for lars anvender antallet af steps i lars proceduren. 
%Vi finder her fra det optimale $\widehat{s}$ 
%Herunder finder vi 
%
%Igen deler vi den op i 
%
%this is the number of steps in lars procedure
%
%
%#  Function produces one fit at each new variable entry.
%# Cross-Validation for LASSO chops up the L1-norm into sequence of 100 points. 
%#  SE for CV is found from the sample SE of the squared errors.  NOT from rerunning CV multiple times.
%# Therefore CV may be inappropriate for small n.  Use Cp from Ssummary() instead.
%

%I den her sektion anvender vi lars algoritmen med to modifikationer, som er beskrevet i sektionerne ... .,til at estimerer lasso og elastik net
%Vi anvender funktionerne \texttt{lars} og \texttt{elnet} fra R-pakkerne af hhv. samme navn.
%
%\subsubsection{Krydsvalidering}
%I denne sektion anvender funktionerne  \texttt{cv.lars} og \texttt{cv.enet} fra R pakkerne \texttt{lars} og \texttt{elnet}. 
%I ligning 
%
%Vi kan se på figur \ref{fig:lars_lasso} at jo laverer vores L1 norm er, jo større krydsvalideringsfejl får vi.  
%
%\imgfigh{lars_lasso.pdf}{0.7}{10-fold krydsvaliderings fejl plottede som en function af fraktion af side L1 norm. De stiplede linjer indikerer minimum fejl, samt fejlen med en standard afvigelse af minimum}{lars_lasso}
%
%I tabel \ref{tab:lars_tab} ser vi ikke samme tendens som ved coordinate descent. 
%Vi ser nemlig ikke en reducering af antal parameter, hvis vi anvende r$\lambda_{1\text{sd}}$.
%Derfor anvender vi $\lambda_{\min}$, da den har mindst krydsvaliderings fejl samt mindre kompleksitet. 
%
%\input{fig/tab/cv_lars_tab}
%
%\input{fig/tab/lars_ud}
%
%Tabellen viser hvilken variable lasso udvælger, og igen kan vi se at hovedparten af variablerne er i samme gruppe, som vores responsvariable. 
%Trods, at vi har to løsnings metoder for lasso vælger de forholdsvis de samme variable.
%
%
%
%Som tidligere beskrevet kan vi for et fast $\lambda_2$ løse elastik net problemet med LARS-EN algoritmen. 
%Vi udregner
%anvender vi sekvens af værdier for $\lambda_2$, som 
%
%\subsubsection{BIC}
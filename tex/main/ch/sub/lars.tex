\section{LARS}
Herefter anvendes LARS algoritmen uden og med lasso modifikationen, hvortil vi anvender \Rlang-pakken \texttt{lars}.

For LARS algoritmen uden lasso modifikationen tilføjes en variabel i hvert step og dermed udfører algoritmen 126 steps.
LARS algoritmen med lasso modifikationen udfører 192 steps, hvor variabler kan tilføjes og fjernes igen.

\subsection{Krydsvalidering}
For at finde den optimale model udføres krydvalidering.
For LARS algoritmen uden lasso modifikationen betragtes antallet af steps, som betegnes \(s\). 
Igen finder vi $\widehat{s}_{\min}$, som angiver den mindste gennemsnitlige krydsvalideringsfejl og $\widehat{s}_{\text{1sd}}$ som betegner den mindste værdi således at fejlen er indenfor en standard afvigelse. 

For LARS algoritmen med lasso modifikationen betragtes en såkaldt fraction af \(\ell_1\)-norm, der er givet ved \(\frac{\vert \tbeta \vert}{\max \vert \tbeta \vert}\).
Vi betragter en følge af 100 værdier af fraction af \(\ell_1\)-norm mellem 0 og 1, hvorudfra vi finder $\widehat{f}$.
Igen betragtes \(\widehat{f}_{\min}\) og \(\widehat{f}_{\text{1sd}}\).


%Vi finder $\widehat{s}$, som betegner antallet af steps, ved krydsvalidering, men igen ser vi ikke kun på  $\widehat{s}_{\min}$, som giver den mindste gennemsnitlige krydsvaliderings fejl, men også den mindste værdi således at fejlen er indenfor en standard afvigelse, som betegnes $\widehat{s}_{\text{1sd}}$. 
%Krydsvalideringen for lasso deler L1-normen op i en følge af 100 punkter mellem 0 og 1, hvor vi herefter finder $\widehat{f}$. Vi ser ikke kun på den model der giver den mindste krydsvaliderings fejl, som betegnes  $\widehat{f}_{\min}$, men også  $\widehat{f}_{\text{1sd}}$ . 

Figur \ref{fig:lars_kryds} viser krydsvalideringskurven og standardfejl som funktion af steps for LARS algoritmen og som funktion af fraction af \(\ell_1\)-norm for LARS algoritmen med lasso modifikationen. 
\imgfigh{lars_kryds.pdf}{1}{10-fold krydsvalideringsfejl som funktion af steps for LARS algoritmen og som funktion af fraction af \(\ell_1\)-norm for LARS algoritmen med lasso modifikationen. De stiplede linjer indikerer værdier af henholdsvis \(s\) og \(f\) med den mindste krydsvalideringsfejl og den mindste værdi af \(s\) og \(f\) således at fejlen er indenfor en standard afvigelse af minimum.}{lars_kryds}
%
Tabel \ref{tab:lars_lasso_tab} giver antallet af steps, gennemsnitlige krydsvalideringsfejl og antallet af variable for LARS algoritmen for \(s_\text{min}\) og \(s_{1 \text{sd}}\) og fraction af \(\ell_1\)-norm, gennemsnitlige krydsvalideringsfejl og antallet af variable for LARS algoritmen med lasso modifikationen for \(f_\text{min}\) og \(f_{1 \text{sd}}\).
Krydsvalideringen fejlen afviger først på 5. decimal, derfor vælger vi modellerne med det mindste antal variable. ---
%
\input{fig/tab/lars_lasso_tab}
%
\imgfigh{coef_lars_kryds.pdf}{1}{h}{coef_lars_kryds}
%

\newpage
\subsection{Inferens}
Lars algoritmen udfører 126 steps, hvor én variabel tilføjes i hvert step.
Funktionen \texttt{larInf} fra \Rlang-pakken \texttt{selectiveInference} udregner \(p\)-værdier og konfidensintervaller for LARS algoritmen.
I tabel \ref{tab:larInf} vises resultaterne.
%
\input{fig/tab/larInf}
%

\subsubsection{Kovarians test}
Som nævnt udfører LARS algoritmen med lasso modifikationen 192 steps, hvori variablerne tilføjes og nogle fjernes igen.
For \(\lambda_\text{min} = 36\) findes 21 prædiktorer, hvorpå kovarians testen udføres.
Tabel \ref{tab:covTest} viser resultatet af dette.
For prædiktorerne valgt i step 1-5 afvises nulhypotesen, hvilket betyder, at ...?
%
\input{fig/tab/covTest}
%



%SE for CV is found from the sample SE of the squared errors
%choose fraction based 1-se cv error rule
%# largest value of lambda such that
%# error is within 1 standard error of the minimum:
%Krydsvalideringen for lars anvender antallet af steps i lars proceduren. 
%Vi finder her fra det optimale $\widehat{s}$ 
%Herunder finder vi 
%
%Igen deler vi den op i 
%
%this is the number of steps in lars procedure
%
%
%#  Function produces one fit at each new variable entry.
%# Cross-Validation for LASSO chops up the L1-norm into sequence of 100 points. 
%#  SE for CV is found from the sample SE of the squared errors.  NOT from rerunning CV multiple times.
%# Therefore CV may be inappropriate for small n.  Use Cp from Ssummary() instead.
%

%I den her sektion anvender vi lars algoritmen med to modifikationer, som er beskrevet i sektionerne ... .,til at estimerer lasso og elastik net
%Vi anvender funktionerne \texttt{lars} og \texttt{elnet} fra R-pakkerne af hhv. samme navn.
%
%\subsubsection{Krydsvalidering}
%I denne sektion anvender funktionerne  \texttt{cv.lars} og \texttt{cv.enet} fra R pakkerne \texttt{lars} og \texttt{elnet}. 
%I ligning 
%
%Vi kan se på figur \ref{fig:lars_lasso} at jo laverer vores L1 norm er, jo større krydsvalideringsfejl får vi.  
%
%\imgfigh{lars_lasso.pdf}{0.7}{10-fold krydsvaliderings fejl plottede som en function af fraktion af side L1 norm. De stiplede linjer indikerer minimum fejl, samt fejlen med en standard afvigelse af minimum}{lars_lasso}
%
%I tabel \ref{tab:lars_tab} ser vi ikke samme tendens som ved coordinate descent. 
%Vi ser nemlig ikke en reducering af antal parameter, hvis vi anvende r$\lambda_{1\text{sd}}$.
%Derfor anvender vi $\lambda_{\min}$, da den har mindst krydsvaliderings fejl samt mindre kompleksitet. 
%
%\input{fig/tab/cv_lars_tab}
%
%\input{fig/tab/lars_ud}
%
%Tabellen viser hvilken variable lasso udvælger, og igen kan vi se at hovedparten af variablerne er i samme gruppe, som vores responsvariable. 
%Trods, at vi har to løsnings metoder for lasso vælger de forholdsvis de samme variable.
%
%
%
%Som tidligere beskrevet kan vi for et fast $\lambda_2$ løse elastik net problemet med LARS-EN algoritmen. 
%Vi udregner
%anvender vi sekvens af værdier for $\lambda_2$, som 
%
%\subsubsection{BIC}
\section{Post-selection inferens for lasso}
I dette afsnit beskrives teste til inferens efter variabeludvælgelse med en adaptiv metode.
Teorien omkring post-selection inferens er udviklet i nyere tid og er stadig under udvikling.
\texttt{R}-pakkerne \texttt{covTest} og \texttt{selectiveInference} understøtter testene, som beskrives i dette afsnit.
\newpage
\input{main/ch/sub/covarians_test}

\subsection{Teste baseret på polyhedral lemmaet} \label{subsec:teste_polyhedron}
I dette afsnit introduceres \textit{TG testen}, hvor TG står for ``truncated gaussian`` som er baseret på polyhedral lemmaet. 
Afsnit er baseret på \citep{post_inference}.

Indledningsvis introduceres notation, som anvendes i dette afsnit.
For en matrix \(M \in \R^{n \times p}\) og liste \(S = \sbr{s_1, \ldots, s_r} \subseteq \sbr{1, \ldots, p}\), skriver vi \(M_S \in \R^{n \times \vert S \vert}\) for submatricen, som findes ved at udtrække de tilhørende kolonner af \(M\) i den givne rækkefølge.
Tilsvarende for en vektor \(x \in \R^p\), betegnes \(x_S\) for subvektoren.
Vi skriver \(\del{M^T M}^+\) for Moore Penrose pseudoinverse af den kvadratiske matrix \(M^T M\) og \(M^+ = \del{M^T M}^+ M^T\) for pseudoinverse af en rektangulær matrix \(M\).
Vi anvender \(P_L\) for projektions operatoren på det lineære underrum \(L\).
Lad \(\mathbb{P}_{\teta^T \tmu = 0} \del{\cdot \given \y \in \mathcal{P}} \) være sandsynlighedsmålet under \(\tmu\) for hvilket \(\teta^T \tmu =0 \) betinget \(\y \in \mathcal{P}\). 

Antag \(\y \sim N(\tmu, \Sigma)\), hvor \(\tmu \in \R^{n}\) er ukendt, men \(\Sigma \in \R^{n \times n}\) er kendt.
Dette generaliserer vores setup i \eqref{eq:set-up}.
Vi betragter polyhedronen \(\mathcal{P} = \cbr{\y : \ \Gamma \y \geq u}\), hvor \(\Gamma \in \mathbb{R}^{m \times n}\) og \(u \in \mathbb{R}^m\) er faste og uligheden skal fortolkes elementvis.
For et fast \(\teta \in \R^n\) ønsker vi at lave inferens af \(\teta^T \tmu\) betinget \(\y \in \mathcal{P}\).
Nedenfor gives en alternativ repræsentation af \(\mathcal{P}\).



%Antag \(\y \sim N\del{\boldsymbol{\mu}, \sigma^2 \mathbf{I}_{n \times n}}\) og at vi ønsker at lave inferens betinget på hændelsen \(\cbr{\mathbf{A} \y \leq b}\).
%Mere præcis ønsker vi at lave inferens om \(\boldsymbol{\eta}^T \boldsymbol{\mu}\), hvor \(\boldsymbol{\eta}\) muligvis afhænger af udvægelsen.
%Hvis lasso, LARS .. har udvalgt denne mængde, da kan vi udføre inferens  af de udvalgte variable.
%Vi kunne eventuelt være interesseret i regressions koefficienterne af \(\y\) på \(\X_\mathcal{A}\), dvs \(\hat{\theta}= \del{\X_\mathcal{A}^T \X_\mathcal{A}}^{-1} \X_\mathcal{A}^T \y\).
%Disse svarer til populations parametrene \(\theta= \del{\X_\mathcal{A}^T \X_\mathcal{A}}^{-1} \X_\mathcal{A}^T \boldsymbol{\mu}\), koefficienterne af projectionen af \(\boldsymbol{\mu}\) på \(\X_\mathcal{A}\).
%Dermed kunne \(\boldsymbol{\eta}^T \boldsymbol{\mu}\) svarer til én af disse koefficienter, og dermed er \(\boldsymbol{\eta}\) en af kolonnerne af \(\X_\mathcal{A} \del{\X_\mathcal{A}^T \X_\mathcal{A}}^{-1}\). Dette eksempel fortsættes senere.

%\subsubsection{Conditioning on a single polyhedron}
%Antag \(\y \sim N \del{\boldsymbol{\mu}, \Sigma}\) og \(\boldsymbol{\eta} \in \mathbb{R}^n\) er en potential retning.
%For at forstå fordelingen af
%\begin{align*}
%\boldsymbol{\eta}^T \y \given \cbr{ \mathbf{A} \y \leq b},
%\end{align*}
%kan vi omskrive \(\cbr{\mathbf{A} \y \leq b}\) udfra \(\boldsymbol{\eta}^T \y\) og en komponent \(\mathbf{z}\) som er uafhængig af \(\boldsymbol{\eta}^T \y\). Denne komponent er givet ved
%\begin{align}
%\mathbf{z} = \del{\mathbf{I} - \mathbf{c} \boldsymbol{\eta}^T} \y, \label{eq:z}
%\end{align}
%hvor 
%\begin{align}
%\mathbf{c} = \Sigma \boldsymbol{\eta} \del{\boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{-1}. \label{eq:c}
%\end{align}
%Det ses let, at \(\mathbf{z}\) er ukorreleret og dermed uafhængig af \(\boldsymbol{\eta}^T \y\).
%Hvis \(\Sigma = \sigma^2 \mathbf{I}\), da er \(\mathbf{z}\) blot residualen \(\del{\mathbf{I} - P_{\boldsymbol{\eta}}} \y \) fra projektionen \(\y\) på \(\boldsymbol{\eta}\).
%Vi kan nu omskrive \(\cbr{\mathbf{A} \y \leq b}\) udfra \(\boldsymbol{\eta}^T \y\) og \(\mathbf{z}\).
%
\begin{lem}[Polyhedral lemma] \label{lem:polyhedral}
%Lad \(\mathbf{z}\) være defineret som i \eqref{eq:z} og \(\mathbf{c}\) som i \eqref{eq:c}. 
For ethvert \(\Sigma\) og \(\teta\), således at \(\teta^T \Sigma \teta \neq 0\), gælder, at
\begin{align}
\Gamma \y \geq u \ \Longleftrightarrow \ \mathcal{V}^- \del{\y} \leq \boldsymbol{\eta}^T \y \leq \mathcal{V}^+ \del{\y}, \  \mathcal{V}^0 \del{\y} \leq 0, \label{eq:post_8}
\end{align}
hvor
\begin{align}
\mathcal{V}^- \del{\y} &= \max_{j: \rho_j > 0} \frac{u_j - \del{\Gamma \y}_j + \rho_j \boldsymbol{\eta}^T \y}{\rho_j}, \label{eq:V-} \\
\mathcal{V}^+ \del{\y} &= \min_{j: \rho_j < 0} \frac{u_j - \del{\Gamma \y}_j + \rho_j \boldsymbol{\eta}^T \y}{\rho_j}, \label{eq:V+} \\
\mathcal{V}^0 \del{\y} &= \max_{j: \rho_j = 0} \del{u_j - \del{\Gamma \y}_j}, \label{eq:V0} 
\end{align}
og \(\rho=\frac{\Gamma \Sigma \boldsymbol{\eta}}{\teta^T \Sigma \teta}\).
Yderligere  er \(\boldsymbol{\eta}^T \y\) og \(\del{\mathcal{V}^-\del{\y}, \mathcal{V}^+\del{\y},\mathcal{V}^0\del{\y}}\) uafhængige. 
\end{lem}
%\begin{proof}
%Vi kan dekomponere \(\y = \mathbf{c} \del{\boldsymbol{\eta}^T \y} + \mathbf{z}\) og opskrive polyhedronet som følgende
%\begin{align*}
%\cbr{\mathbf{A} \y \leq b} &= \cbr{\mathbf{A} \del{\mathbf{c} \del{\boldsymbol{\eta}^T \y} + \mathbf{z}} \leq b} \\
%&= \cbr{\mathbf{A} \mathbf{c} \del{\boldsymbol{\eta}^T \y} \leq b - \mathbf{A} \mathbf{z} } \\
%&= \cbr{\del{\mathbf{A} \mathbf{c}}_j \del{\boldsymbol{\eta}^T \y} \leq b_j - \del{\mathbf{A} \mathbf{z}}_j \text{ for alle } j} \\
%&= \begin{cases}
%\boldsymbol{\eta}^T \y \leq \frac{b_j - \del{\mathbf{A} \mathbf{z}}_j}{\del{\mathbf{A} \mathbf{c}}_j}, \quad j:\del{\mathbf{A} \mathbf{c}}_j > 0 \\
%\boldsymbol{\eta}^T \y \geq \frac{b_j - \del{\mathbf{A} \mathbf{z}}_j}{\del{\mathbf{A} \mathbf{c}}_j}, \quad j:\del{\mathbf{A} \mathbf{c}}_j < 0 \\
%0 \leq b_j - \del{\mathbf{A} \mathbf{z}}_j, \quad j:\del{\mathbf{A} \mathbf{c}}_j = 0
%\end{cases}.
%\end{align*}
%Da \(\boldsymbol{\eta}^T \y \) er den samme mængde for alle \(j\), må det mindste være maksimum af de nedre grænser, som er \(\mathcal{V}^- \del{\mathbf{z}}\), og ikke mere end minimum af de øvre grænser, som er \(\mathcal{V}^+ \del{\mathbf{z}}\).
%\end{proof}
Resultatet i \eqref{eq:post_8} hvor \(\mathcal{V}^-\), \(\mathcal{V}^+\) og \(\mathcal{V}^0\) defineres i \eqref{eq:V-}-\eqref{eq:V0} er deterministisk og gælder for alle \(\y\).
Blot uafhængighedsresultatet afhænger af normaliteten af \(\y\).
Se figur \ref{fig:polyhedron} for en geometrisk illustration af lemmaet.
Intuitivt kan resultatet forklares som følgende, hvor vi antager, at \(\Sigma= \mathbf{I}\).
Først dekomponeres \(\y=P_{\boldsymbol{\eta}} \y + P_{\boldsymbol{\eta}^\perp} \y\), hvor \(P_{\boldsymbol{\eta}} \y = \frac{\boldsymbol{\eta} \boldsymbol{\eta}^T \y}{\Vert \boldsymbol{\eta} \Vert_2^2}\) er projektionen af \(\y\) langs \(\boldsymbol{\eta}\) og \(P_{\boldsymbol{\eta}^\perp} \y = \y - P_{\boldsymbol{\eta}} \y\) er projektionen på det ortogonale komplement af \(\boldsymbol{\eta}\).
Vi kan betragte \(\y\) som en afvigelse fra \(P_{\boldsymbol{\eta}^\perp} \y\) af størrelsen \(\boldsymbol{\eta}^T \y\), langs linjen bestemt af \(\boldsymbol{\eta}\).
Mængderne \(\mathcal{V}^-\) og \(\mathcal{V}^+\) bestemmer, hvor langt vi kan afvige på hver side af \(P_{\boldsymbol{\eta}^\perp} \y\), inden \(\y\) forlader polyhedronen, hvoraf vi får uligheden \(\mathcal{V}^- \leq \boldsymbol{\eta}^T \y \leq \mathcal{V}^+\).
Nogle flader af polyhedronen kan være perfekt justeret med \(\boldsymbol{\eta}\), dvs deres normal vektorer kan være ortogonale med \(\boldsymbol{\eta}\).
Dette kan tjekkes udfra \(\mathcal{V}^0\) ved at \(\y\) ligger på den rigtige side af disse flader.  
%--
%Betinget \(P_{\boldsymbol{\eta}^\perp} \y\), ses at hændelsen \(\cbr{\mathbf{A} \y \leq b}\) er ækvivalent med hændelsen \(\mathcal{V}^- \del{\y} \leq \boldsymbol{\eta}^T \y \leq \mathcal{V}^+ \del{\y}\). Yderligere er \(\mathcal{V}^- \del{\y}\) og \(\mathcal{V}^+ \del{\y}\) uafhængige af \(\boldsymbol{\eta}^T \y\), da disse kun er funktioner af \(P_{\boldsymbol{\eta}^\perp} \y\), som er uafhængige af \(\y\).
%--

%
\begin{figure}[H]
\centering
\scalebox{1}{\input{fig/polyhedron.tikz}}
\caption{Geometri af polyhedron udvælgelsen som trunkering. For simplicitet antages at \(\Sigma = \mathbf{I}\). Det blå område er polyhedron mængden \(\cbr{\y : \ \Gamma \y \geq u}\).
Ved at opdele \(\y\) til dens projektion på \(\teta\) og dens projektion på det ortogonale komplement af \(\teta\), ses at \(\Gamma \y \geq u\) er opfyldt, hvis og kun hvis \(\teta^T \y\) ikke afviger for langt fra \(P_{\boldsymbol{\eta}^\perp} \y\), dvs den skal fastholdes imellem grænserne \(\mathcal{V}^-\) og \(\mathcal{V}^+\).
Yderligere er grænserne \(\mathcal{V}^-\) og \(\mathcal{V}^+\) kun funktioner af \(P_{\boldsymbol{\eta}^\perp} \y\), derfor er de uafhængige af \(\teta^T \y\) under normalitet.} \label{fig:polyhedron}
\end{figure}
%

Af lemma \ref{lem:polyhedral} kan fordelingen af enhver lineær funktion \(\boldsymbol{\eta}^T \y\) betinget \(\Gamma \y \geq u\) skrives som følgende betinget fordeling
\begin{align*}
\boldsymbol{\eta}^T \y \given \mathcal{V}^- \del{\y} \leq \boldsymbol{\eta}^T \y \leq \mathcal{V}^+ \del{\y}, \ \mathcal{V}^0 \del{\y} \leq 0.
\end{align*}
Da \(\boldsymbol{\eta}^T \y\) er normalfordelt, er overstående trunkeret normalfordelt.
%En simpel transformation fører til pivotal statistic, som er kritisk for inferens af \(\boldsymbol{\eta}^T \tmu\).

\begin{lem}  \label{lem:lem2}
Lad \(\Phi \del{x}\) betegne fordelingsfunktionen af en standard normalfordeling, da er fordelingsfunktionen for en normalfordeling med middelværdi \(\mu\) og varians \(\sigma^2\) af en stokastisk variable indenfor intervallet \(\sbr{a,b}\) givet ved
\begin{align*}
F_{\mu, \sigma^2}^{\sbr{a,b}} \del{x} = \frac{\Phi\del{\frac{x-\mu}{\sigma}} - \Phi\del{\frac{a-\mu}{\sigma}}}{\Phi\del{\frac{b-\mu}{\sigma}} - \Phi\del{\frac{a-\mu}{\sigma}}}.
\end{align*}
For \(\boldsymbol{\eta}^T \Sigma \boldsymbol{\eta} \neq 0\), da følger  \(F_{\boldsymbol{\eta}^T \tmu, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{\sbr{\mathcal{V}^-,\mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y} \) betinget \(\Gamma \y \geq u\) en standard uniform fordeling, dvs
\begin{align*}
\mathbb{P} \del{F_{\boldsymbol{\eta}^T \tmu, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{\sbr{\mathcal{V}^-,\mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y} \leq \alpha \given \Gamma \y \geq u} = \alpha, 
\end{align*}
for ethvert \(0 \leq \alpha \leq 1\), hvor \(\mathcal{V}^-\) og \(\mathcal{V}^+\) er defineret i \eqref{eq:V-} samt \eqref{eq:V+}. 
\end{lem}
%
Dette fører til gyldige betinget \(p\)-værdier for at teste nulhypotesen \(\hyp_0: \boldsymbol{\eta}^T \boldsymbol{\mu}=0\) og tilhørende betinget konfidensintervaller for \(\boldsymbol{\eta}^T \tmu\).
Herefter betragtes one-sided inferens efterfulgt af two-sided inferens.
%
\begin{lem} \label{lem:lem3}
Givet \(\boldsymbol{\eta}^T \Sigma \boldsymbol{\eta} \neq 0\), antag at vi vil teste
\begin{align*}
\hyp_0: \boldsymbol{\eta}^T \tmu=0 \quad \text{imod} \quad \hyp_1: \boldsymbol{\eta}^T \tmu > 0.
\end{align*}
Definer teststørrelsen
\begin{align}
T=1- F_{0, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{\sbr{\mathcal{V}^-, \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y}, \label{eq:post_1.14}
\end{align}
hvor fordelingsfunktionen af \(\boldsymbol{\eta}^T \y \sim N \del{0,  \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}\) i intervallet \(\sbr{\mathcal{V}^-, \mathcal{V}^+}\) er givet i lemma \ref{lem:lem2}.
Da er \(T\) en gyldig \(p\)-værdi for \(\hyp_0\) betinget \(\Gamma \y \geq u\)
\begin{align}
\mathbb{P}_{\boldsymbol{\eta}^T \tmu=0} \del{T \leq \alpha \given \Gamma \y \geq u} = \alpha, \label{eq:post_1.15}
\end{align}
for ethvert \(0 \leq \alpha \leq 1\). 
Definer \(\delta_{\alpha}\), som opfylder, at
\begin{align}
1-F_{\delta_{\alpha}, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{\sbr{\mathcal{V}^- \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y} &= \alpha. \label{eq:post_1.16}
\end{align}
Da er \(I= [\delta_\alpha, \infty )\) et gyldig one-sided konfidensinterval for \(\teta^T \tmu\) betinget \(\Gamma \y \geq u\)
\begin{align}
\mathbb{P} \del{\boldsymbol{\eta}^T \tmu \geq \delta_\alpha \given \Gamma \y \geq u} = 1- \alpha. \label{eq:post_1.17}
\end{align}
\end{lem}
%
Af teststørrelsen i \eqref{eq:post_1.14} har vi magt imod one-sided alternativ hypotese \(\hyp_1 : \teta^T \tmu > 0\), da den trunkerede normal overlevelsesfunktion \(1-F_{\mu, \sigma^2}^{\sbr{a,b}} \del{x}\), evalueret i ethvert fast punkt \(x\), er monoton stigende i \(\mu\) (se ).
Dette gælder også for konfidensintervallet i \eqref{eq:post_1.16} og \eqref{eq:post_1.17}.
Herefter betragtes two-sided inferens.
%
\begin{lem} \label{lem:lem4}
Givet \(\boldsymbol{\eta}^T \Sigma \boldsymbol{\eta} \neq 0\), antag at vi vil teste
\begin{align*}
\hyp_0: \boldsymbol{\eta}^T \tmu=0 \quad \text{imod} \quad \hyp_1: \boldsymbol{\eta}^T \tmu \neq 0.
\end{align*}
Definer teststørrelsen
\begin{align}
T=2 \cdot \min\cbr{F_{0, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{\sbr{\mathcal{V}^-, \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y}, 1 - F_{0, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{\sbr{\mathcal{V}^-, \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y}}, \label{eq:post_1.18}
\end{align}
hvor fordelingsfunktionen af \(\boldsymbol{\eta}^T \y \sim N \del{0,  \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}\) i intervallet \(\sbr{\mathcal{V}^-, \mathcal{V}^+}\) er givet i lemma \ref{lem:lem2}.
Da er \(T\) en gyldig \(p\)-værdi for \(\hyp_0\) betinget \(\Gamma \y \geq u\)
\begin{align}
\mathbb{P}_{\boldsymbol{\eta}^T \tmu=0} \del{T \leq \alpha \given \Gamma \y \geq u} = \alpha, \label{eq:post_1.19}
\end{align}
for ethvert \(0 \leq \alpha \leq 1\). 
Definer \(\delta_{\frac{\alpha}{2}}, \delta_{1-\frac{\alpha}{2}}\) som opfylder, at
\begin{align}
1-F_{\delta_{\frac{\alpha}{2}}, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta}}^{\sbr{\mathcal{V}^- \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y} &= \frac{\alpha}{2}, \label{eq:post_20} \\
1-F_{\delta_{1-\frac{\alpha}{2}}, \boldsymbol{\eta}^T \Sigma \boldsymbol{\eta} }^{\sbr{\mathcal{V}^- \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y} &= 1-\frac{\alpha}{2}. \label{eq:post_21}
\end{align}
Da gælder, at
\begin{align}
\mathbb{P} \del{\delta_{\frac{\alpha}{2}} \leq  \boldsymbol{\eta}^T \tmu \leq \delta_{1-\frac{\alpha}{2}} \given \Gamma \y \geq u} = 1- \alpha. \label{eq:post_22}
\end{align}
\end{lem}
%
Teststørrelsen i \eqref{eq:post_1.18}, defineret som minimum af den trunkerede normal fordelingsfunktion og overlevelsesfunktionen, har magt imod den alternative hypotese \(H_1: \boldsymbol{\eta}^T \tmu \neq 0\).
Beviset for dens nulhypotese i \eqref{eq:post_1.19} kommer af, at hvis \(U\) følger en standard uniform fordeling, da gør \(2 \cdot \min \cbr{U,1-U}\) også.
Konstruktionen af konfidensintervallet i \eqref{eq:post_20}, \eqref{eq:post_21} og \eqref{eq:post_22} anvender igen monotonicitet af en trunkeret normal overlevelsesfunktion i den underliggende middelværdi parameter.

Vi antager, at kolonnerne af \(\X\) er i general position (se definition \ref{defn:general_position}), hvilket medfører at løsningsstierne for LARS og lasso er entydige \citep{lasso_unique}. 
Herefter vil vi vise at modeludvælgelsen for LARS og lasso kan karakteriseres som et polyhedron (dvs kegler) på formen \(\cbr{\y : \ \Gamma \y \geq 0}\).
Efter dette beskrives formene af de eksakte betinget tests og intervaller, som er givet i lemma \ref{lem:polyhedral}-\ref{lem:lem4} for LARS og lasso.
APPENDIKS

Givet antallet af steps \(k\), da kan vi let udregne betinget \(p\)-værdier og konfidensintervaller, efter vi har konstrueret matricen \(\Gamma\) for henholdsvis LARS eller lasso.
Lad os teste nulhypotesen \(\hyp_0: \ \teta^T \tmu = 0\), hvor \(\teta\) er vilkårlig.

Som specificeret i lemma \ref{lem:polyhedral} udregnes først mængderne
\begin{align*}
\mathcal{V}^- \del{\y} &=  \max_{j: \rho_j > 0} \frac{- \del{\Gamma \y}_j}{\rho_j} + \boldsymbol{\eta}^T \y = \max_{j: \del{\Gamma \teta}_j > 0} - \del{\Gamma \y}_j \cdot \frac{\Vert \teta \Vert_2^2}{\del{\Gamma \teta}_j} + \teta^T \y, \\
\mathcal{V}^+ \del{\y} &=\min_{j: \del{\Gamma \teta}_j < 0} - \del{\Gamma \y}_j \cdot \frac{\Vert \teta \Vert_2^2}{\del{\Gamma \teta}_j} + \teta^T \y.
\end{align*}
Antallet af operationer som kræves for at udregne \(\mathcal{V}^-\) og \(\mathcal{V}^+\) er \(O \del{mn}\), hvor \(m\) er antallet af rækker i \(\Gamma\).

For at teste imod en one-sided alternativ hypotese \(\hyp_1: \ \teta^T \tmu > 0\),  defineres teststørrelsen
\begin{align*}
T_k^\text{tg}=1- F_{0, \sigma^2 \Vert \boldsymbol{\eta} \Vert_2^2}^{\sbr{\mathcal{V}^-, \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y} = \frac{\Phi \del{\frac{\mathcal{V}^+}{\sigma \Vert \boldsymbol{\eta} \Vert_2}}-\Phi \del{\frac{\boldsymbol{\eta}^T \y}{\sigma  \Vert \boldsymbol{\eta} \Vert_2}}}{\Phi \del{\frac{\mathcal{V}^+}{\sigma  \Vert \boldsymbol{\eta} \Vert_2}}-\Phi \del{\frac{\mathcal{V}^-}{\sigma \Vert \boldsymbol{\eta} \Vert_2}}}.
\end{align*}
Af lemma \ref{lem:lem3} giver dette en gyldig \(p\)-værdi betinget udvælgelsen, dvs
\begin{align}
\mathbb{P}_{\boldsymbol{\eta}^T \tmu = 0} \del{T_k^\text{tg} \leq \alpha \given \hat{\A}_k \del{\y} = \A_k, \hat{s}_{\A_k} \del{y} = s_{\A_k}} = \alpha, \label{eq:post_32}
\end{align}
for ethvert \(0 \leq \alpha \leq 1\).
Vi definer  \(\delta_\alpha\), som opfylder, at \(1-F_{\delta_{\alpha}, \sigma^2 \Vert \boldsymbol{\eta} \Vert_2^2}^{\sbr{\mathcal{V}^- \mathcal{V}^+}} \del{\boldsymbol{\eta}^T \y} = \alpha\).
Vi lader \(I_k = [\delta_\alpha, \infty)\), hvoraf vi får et gyldigt one-sided konfidensinterval
\begin{align}
\mathbb{P} \del{\boldsymbol{\eta}^T \tmu \in I_k \given \hat{\A}_k \del{\y} = \A_k, \hat{s}_{\A_k} \del{\y} = s_{\A_k}} = 1-\alpha. \label{eq:post_33}
\end{align}

For at teste imod en two-sided alternativ hypotese \(\hyp_1: \ \teta^T \tmu \neq 0\), betragtes teststørrelsen
\begin{align*}
T_k^\text{TG}= 2 \cdot \min \cbr{T_k^{\text{tg}}, 1-T_k^{\text{tg}}}.
\end{align*}
Af lemma \ref{lem:lem4} fås samme resultaterne i \eqref{eq:post_32} og \eqref{eq:post_33}, men hvor \(T_k^\text{tg}\) erstattes med \(T_k^\text{TG}\) og \(I_k\) erstattes med \(I_k'= \sbr{\delta_{\frac{\alpha}{2}}, \delta_{1-\frac{\alpha}{2}}}\).

Hvis \(\teta = \del{\X_{\A_k}^+}^T e_k\), hvor \(e_k\) er den \(k\)'te enhedsvektor, da kan nulhypotesen \(\hyp_0: \ \teta^T \tmu =0\) omskrives til
\begin{align*}
\boldsymbol{\eta}^T \boldsymbol{\mu} = \mathbf{e}_k^T \X_{\A_k}^+ \boldsymbol{\mu} = \mathbf{e}_k^T \del{\X^T \X}^{-1} \X^T \X \boldsymbol{\beta} = \beta_k,
\end{align*}
dvs nulhypotesen svarer til at teste om \(k\)'te variabel er signifikant.
%Da testes om koefficienten af dem sidste valgte variabel, i regressionen af \(tmu\) på \(\X_{\A_k}\), er lig 0.

For at bestemme om vi kan betragte en one-sided eller two-sided nulhypotesen.
For \(\teta = \del{\X_{\A_k}^+}^T e_k\), er one sided setup \(\hyp_0: \eta^T \tmu = 0\) og  \(\hyp_0: \eta^T \tmu > 0\), som ikke giver mening, da der ikke er grund til at tro at \(k\)'te regressions koefficient \(\mathbf{e}_k^T \X_{\A_k}^+ \boldsymbol{\mu}\) skal være positiv.
Hvis istedet \(\teta = s_k \del{\X_{\A_k}^+}^T e_k\), hvor \(s_k\) er fortegnet af \(k\)'te variabel som den medtages i LARS eller lasso modellen, da er nulhypotesen \(\hyp_0: s_k e_k^T \X_{\A_k}^+ \tmu = 0\) uændret, men den alternative hypotese \(\hyp_0: s_k e_k^T \X_{\A_k}^+ \tmu > 0\) har nu en konkret fortolkning.
Den siger at regressions koefficienten af den sidst valgte variabel er ikke-nul og har samme fortegn som koefficienten i den fittede model.


Nulhypotesen for TG testen er stokastisk, da \(\mathcal{V}^-\) og \(\mathcal{V}^+\) er stokastiske variable ...
TG testen for lasso antager blot en generel position af kolonnerne af \(\X\), som er en svag antagelse.
Testen kan bruges for ethvert fast \(\lambda\) og er eksakt.

Den resulterende fordeling af teststørrelsen er eksakt og generelt antager TG testen ingen betingelser på model matricen \(\X\) som er tilfældet for kovarians testen.
Spacing testen er en eksakt version af kovarians testen. 
\newpage

\input{main/ch/sub/spacing_test}
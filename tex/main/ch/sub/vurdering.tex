\chapter{Out-of-sample} \label{ch:out-of-sample}
I dette afsnit vil vi betragte modellernes prædiktion.
Som nævnt prædikteres arbejdsløshedsraten one-step-ahead med et rullende forecast, hvor vi udvider estimerings vinduet med én observation. 

Arbejdsløshedsraten og de prædikterede værdier sammenlignes med MAE, MSE og et gennemsnitlig tabs ratio mellem hver model og benchmark modellen for både MAE og MSE.
Som nævnt er faktor modellen valgt udfra IC\(_2\) benchmark model.
Resultaterne af dette er givet i tabel \ref{tab:mae_mse_vurdering}.

\input{fig/tab/mae_mse_vurdering}
Adaptive lasso med lasso vægte (CV) har den mindste MAE og MSE. 
Vi ser dog, at MAE og MSE for modellerne adaptive lasso med OLS (CV), adaptive lasso med OLS (BIC) og adaptive lasso med lasso vægte (BIC) er meget tæt på. 
Generelt kan vi se, at den indbyrdes forskel i MAE og MSE for lasso modellerne og dens generaliseringer er forholdsvis lille.
 
Vi ser, at kun AR(4) og faktor model (IC$_1$) er dårligere end benchmarkmodellen. 

For at vurdere modellernes prædiktion i forhold til benchmark modellen fra måned til måned, betragtes et rullende gennemsnitlig fejl ratio.
Et rullende gennemsnitlig absolut fejl ratio for samtlige modeller illustreres på figur \ref{fig:rolling_mae}.
Heraf ses at AR(4) prædikterer dårligere end benchmark modellen over hele testmængden.
Også faktor modellen valgt udfra IC$_1$ prædiktere dårligere end benchmark modellen med undtagelse af maj, juni og august i 2006.
Derudover ser vi, at ridge regression modellerne prædikterer bedre end benchmark modellen, mens alle lasso baseret modeller klart har bedre prædiktion end de øvrige modeller.
%
\imgfigh{rolling_mae.pdf}{1}{Rullende gennemsnitlige absolutte fejl ratio.}{rolling_mae}
%

%
\imgfigh{rolling_mse.pdf}{1}{Rullende gennemsnitlige kvadrerede fejl ratio.}{rolling_mse}
%

\section{Diebold Mariano test}
I tabel \ref{tab:dm_test} ses resultaterne fra Diebold-Mariano testen, hvor hver model testes imod benchmark modellen.
Heraf ses at nulhypotesen ikke kan afvises for faktor modellen valgt udfra IC\(_1\), hvilket vil sige, at modellen ikke er signifikant forskellig fra benchmark modellen.
For de resterende modeller afvises nulhypotesen, hvilket betyder, at disse ikke er signifikant forskellige fra benchmark modellen.
%
\input{fig/tab/dm_test}
%
\newpage
\section{MCS} 
Herefter vil vi teste alle modellerne imod hinanden, hvortil vi betragter model confidence procedure.
Proceduren udføres for \(\alpha = 0.1\) og \(\alpha = 0.2\), teststørrelserne \(\text{T}_\text{R}\) og \(\text{T}_\text{max}\) og 5000 bootstrapped samples.
I tabel \ref{tab:mcs_tab} er modellerne i 80\% og 90\% MCS angivet for \(\text{T}_\text{R}\) og \(\text{T}_\text{max}\).
Vi har testet for absolutte fejl og kvadrerede fejl, hvilket gav samme resultat.
For alle teste elimineres faktor modellen valgt udfra IC\(_1\) fra MCS.
For teststørrelsen \(\text{T}_\text{R}\) elimineres yderligere ridge regression med CV og BIC for både \(\alpha = 0.1\) og \(\alpha = 0.2\).
For teststørrelsen \(\text{T}_\text{max}\) elimineres foruden faktor modellen valgt udfra IC\(_1\) også LARS algoritmen med lasso modifikation med CV for \(\alpha = 0.2\), men kun faktor modellen valgt udfra IC\(_1\) for \(\alpha = 0.1\).
%
\input{fig/tab/mcs_tab}
%

\section{Oversigt over out-of-sample resultater}
Vi ser, at modellen adaptive lasso med lasso vægte (CV) er den der begår sig bedst i forhold MAE og MSE. 
Der er dog ikke en stor forskel på de resterende 3 adaptive lasso modeller, hvor de også er de modeller med færreste antal parametre. 

Ridge regression, som inkluderer alle variabler, er også dem der prædikterer dårligst af lasso og dens generaliseringer. 
AR(4) er den model, som får de dårligste resultater, hvilket vi nok også havde forventet, da det er en meget simple model. 

Lasso løst med coordinate descent har den mindste MAE og MSE i forhold til lasso løst med LARS. Det er dog ikke den helt store forskel på deres MAE og MSE. 

For hver model estimerede vi tuning parameteren ud fra to forskellige metoder. Vi ser, at lasso, ridge regression, LARS og LARS med lasso modifikation, hvor tuning parameteren er estimeret ud fra BIC har den mindste MAE og MSE i forhold til at anvende krydsvalidering. Det er dog ikke stor en forskel på fejlene og specielt ikke for lasso og dens generaliseringer. 

%Overordnet set præsterer AR(4) dårligst både in- og out-of-sample.
%Faktor modellen valgt udfra IC\(_1\)
%adaptive lasso inkludere kun 2 prædiktorer og er stadig iblandt de bedste modeller.
%For group lasso som inkludere 99 prædiktorerne 119 (CV) og 99 (BIC), hvilket ikke forbedrer prædiktionen fra de øvrige lasso baseret modeller.
%
%Vi ser ikke den store forskel ved at anvende krydsvalidering fremfor BIC
%LARS med lasso modifikation i forhold til lasso 
%
%LARS uden lasso modifikation lader til at præstrere bedre end LARS med lasso modifikation.
%lidt overraskende.
%least angle regression er ikke direkte under lasso modellerne eller shrinkage.


